{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "isInteractiveWindowMessageCell": true
   },
   "source": [
    "Restarted aspire (Python 3.8.18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-23 16:12:36,627 INFO [aspire.source.image] Creating Simulation with 2000 images.\n"
     ]
    }
   ],
   "source": [
    "import aspire\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from aspire.operators import RadialCTFFilter\n",
    "from aspire.source.simulation import Simulation\n",
    "from aspire.volume import LegacyVolume, Volume\n",
    "from utils import volsCovarEigenvec\n",
    "import time\n",
    "from covar_estimation import im_stack_backward\n",
    "import torch\n",
    "# Specify parameters\n",
    "img_size = 15  # image size in square\n",
    "num_imgs = 2000  # number of images\n",
    "dtype = np.float32\n",
    "\n",
    "\n",
    "rank = 1\n",
    "c = rank + 1\n",
    "vols = LegacyVolume(\n",
    "    L=img_size,\n",
    "    C=c,\n",
    "    dtype=dtype,\n",
    ").generate()\n",
    "vols -= np.mean(vols,axis=0)\n",
    "sim = Simulation(\n",
    "    #unique_filters=[RadialCTFFilter(defocus=d) for d in np.linspace(1.5e4, 2.5e4, 7)],\n",
    "    n=num_imgs,\n",
    "    vols=vols,\n",
    "    dtype=dtype,\n",
    "    amplitudes=1,\n",
    "    offsets = 0\n",
    ")\n",
    "\n",
    "vectorsGD = torch.tensor(volsCovarEigenvec(vols).asnumpy(),requires_grad = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from covar_sgd import CovarDataset,Covar,CovarTrainer,dataset_collate\n",
    "cds = CovarDataset(sim,rank = rank)\n",
    "covar = Covar(resolution=img_size,rank=rank,norm_factor=cds.im_norm_factor)#,vectors=vectorsGD)\n",
    "batch_size = 1\n",
    "learning_rate = 1e-4\n",
    "momentum = 0.9\n",
    "device = torch.device('cuda:0')\n",
    "dataloader = torch.utils.data.DataLoader(cds,batch_size = batch_size,shuffle = False,collate_fn=dataset_collate)\n",
    "optimizer = torch.optim.SGD(covar.parameters(),lr = learning_rate,momentum = momentum)\n",
    "trainer = CovarTrainer(covar,dataloader,device,vectorsGD = vectorsGD/cds.im_norm_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 , :   0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cost value : 7.81e-03,  cosine sim : 1.00: 100%|██████████| 2000/2000 [00:12<00:00, 160.64it/s] \n",
      "cost value : 0.00e+00,  cosine sim : 1.00: 100%|██████████| 2000/2000 [00:12<00:00, 164.23it/s] \n",
      "cost value : -7.81e-03,  cosine sim : 1.00:  87%|████████▋ | 1740/2000 [00:10<00:01, 164.55it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSGD\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mreg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/roaiyadgar/thesis/covar_sgd.py:97\u001b[0m, in \u001b[0;36mCovarTrainer.train\u001b[0;34m(self, max_epochs, lr, momentum, optim_type, reg, gamma_lr, gamma_reg, orthogonal_projection)\u001b[0m\n\u001b[1;32m     95\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mStepLR(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer,step_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, gamma \u001b[38;5;241m=\u001b[39m gamma_lr)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_epochs):\n\u001b[0;32m---> 97\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m     reg \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m gamma_reg\n\u001b[1;32m    100\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/home/roaiyadgar/thesis/covar_sgd.py:78\u001b[0m, in \u001b[0;36mCovarTrainer.run_epoch\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m     76\u001b[0m images,nufft_plans \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m     77\u001b[0m images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 78\u001b[0m cost_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnufft_plans\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(batch_ind \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_log_freq \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_training()\n",
      "File \u001b[0;32m/home/roaiyadgar/thesis/covar_sgd.py:64\u001b[0m, in \u001b[0;36mCovarTrainer.run_batch\u001b[0;34m(self, images, nufft_plans)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_batch\u001b[39m(\u001b[38;5;28mself\u001b[39m,images,nufft_plans):\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 64\u001b[0m     cost_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcovar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnufft_plans\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m     cost_val\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m#torch.nn.utils.clip_grad_value_(self.covar.parameters(), 1000) #TODO : check for effect of gradient clipping\u001b[39;00m\n",
      "File \u001b[0;32m/home/roaiyadgar/thesis/covar_sgd.py:140\u001b[0m, in \u001b[0;36mCovar.cost\u001b[0;34m(self, images, nufft_plans)\u001b[0m\n\u001b[1;32m    137\u001b[0m images_projvols_term \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(projected_vols,images\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m    138\u001b[0m projvols_prod_term \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(projected_vols,projected_vols\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m--> 140\u001b[0m cost_val \u001b[38;5;241m=\u001b[39m (norm_images_term \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages_projvols_term\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m             \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(torch\u001b[38;5;241m.\u001b[39mpow(projvols_prod_term,\u001b[38;5;241m2\u001b[39m),dim\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m)))\n\u001b[1;32m    143\u001b[0m cost_val \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(cost_val,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;66;03m#TODO : add regulairzation\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train(10,learning_rate,momentum,'SGD',reg = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cost value : 6.02e+02,  cosine sim : 1.00:  40%|████      | 80/200 [03:05<04:38,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3086.4863, device='cuda:0', grad_fn=<MeanBackward1>) tensor(-0.0007, device='cuda:0', grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "images,plans = cds[:]\n",
    "images = images.to(device)\n",
    "#covar = Covar(resolution=img_size,rank=rank,norm_factor=cds.im_norm_factor)\n",
    "covar = covar.to(device)\n",
    "a = covar.cost(images,plans)\n",
    "\n",
    "covarGD = Covar(resolution=img_size,rank=rank,norm_factor=cds.im_norm_factor,vectors=vectorsGD)\n",
    "covarGD = covarGD.to(device)\n",
    "b = covarGD.cost(images,plans)\n",
    "\n",
    "print(a,b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.02840121]], dtype=float32),\n",
       " array([[-0.03713643]], dtype=float32),\n",
       " array([[-0.07990742]], dtype=float32),\n",
       " array([[-0.19121245]], dtype=float32),\n",
       " array([[-0.42498663]], dtype=float32),\n",
       " array([[-0.6909434]], dtype=float32),\n",
       " array([[-0.7764266]], dtype=float32),\n",
       " array([[-0.7366661]], dtype=float32),\n",
       " array([[-0.67463344]], dtype=float32),\n",
       " array([[-0.6347184]], dtype=float32),\n",
       " array([[-0.6316152]], dtype=float32),\n",
       " array([[-0.68954724]], dtype=float32),\n",
       " array([[-0.7649933]], dtype=float32),\n",
       " array([[-0.80808586]], dtype=float32),\n",
       " array([[-0.8180496]], dtype=float32),\n",
       " array([[-0.8170496]], dtype=float32),\n",
       " array([[-0.8171366]], dtype=float32),\n",
       " array([[-0.82627994]], dtype=float32),\n",
       " array([[-0.85104334]], dtype=float32),\n",
       " array([[-0.8747826]], dtype=float32),\n",
       " array([[-0.8915245]], dtype=float32),\n",
       " array([[-0.90418965]], dtype=float32),\n",
       " array([[-0.9114733]], dtype=float32),\n",
       " array([[-0.92441475]], dtype=float32),\n",
       " array([[-0.9385556]], dtype=float32),\n",
       " array([[-0.9449637]], dtype=float32),\n",
       " array([[-0.95255506]], dtype=float32),\n",
       " array([[-0.9549511]], dtype=float32),\n",
       " array([[-0.9622845]], dtype=float32),\n",
       " array([[-0.9701611]], dtype=float32),\n",
       " array([[-0.9717298]], dtype=float32),\n",
       " array([[-0.97703034]], dtype=float32),\n",
       " array([[-0.9767954]], dtype=float32),\n",
       " array([[-0.9813305]], dtype=float32),\n",
       " array([[-0.9845664]], dtype=float32),\n",
       " array([[-0.9837692]], dtype=float32),\n",
       " array([[-0.9880121]], dtype=float32),\n",
       " array([[-0.9862812]], dtype=float32),\n",
       " array([[-0.9897663]], dtype=float32),\n",
       " array([[-0.9901941]], dtype=float32),\n",
       " array([[0.98968506]], dtype=float32),\n",
       " array([[-0.9929153]], dtype=float32),\n",
       " array([[-0.99058795]], dtype=float32),\n",
       " array([[-0.9940889]], dtype=float32),\n",
       " array([[0.99252063]], dtype=float32),\n",
       " array([[0.99303216]], dtype=float32),\n",
       " array([[-0.99525845]], dtype=float32),\n",
       " array([[-0.9929566]], dtype=float32),\n",
       " array([[-0.99614614]], dtype=float32),\n",
       " array([[0.99455935]], dtype=float32),\n",
       " array([[0.99350744]], dtype=float32),\n",
       " array([[-0.99670607]], dtype=float32),\n",
       " array([[-0.9938801]], dtype=float32),\n",
       " array([[-0.99683]], dtype=float32),\n",
       " array([[0.99464506]], dtype=float32),\n",
       " array([[0.9950982]], dtype=float32),\n",
       " array([[-0.99712414]], dtype=float32),\n",
       " array([[-0.99473566]], dtype=float32),\n",
       " array([[-0.9976391]], dtype=float32),\n",
       " array([[0.99432176]], dtype=float32),\n",
       " array([[0.9964972]], dtype=float32),\n",
       " array([[-0.9969625]], dtype=float32),\n",
       " array([[-0.99560463]], dtype=float32),\n",
       " array([[-0.9979211]], dtype=float32),\n",
       " array([[0.99407315]], dtype=float32),\n",
       " array([[0.9974746]], dtype=float32),\n",
       " array([[-0.9965232]], dtype=float32),\n",
       " array([[-0.9965592]], dtype=float32)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.log_cosine_sim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aspire",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
