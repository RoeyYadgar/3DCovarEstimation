{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "isInteractiveWindowMessageCell": true
   },
   "source": [
    "Restarted aspire (Python 3.8.18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-20 11:39:57,992 INFO [aspire.source.image] Creating Simulation with 2000 images.\n"
     ]
    }
   ],
   "source": [
    "import aspire\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from aspire.operators import RadialCTFFilter\n",
    "from aspire.source.simulation import Simulation\n",
    "from aspire.volume import LegacyVolume, Volume\n",
    "from utils import volsCovarEigenvec\n",
    "import time\n",
    "import torch\n",
    "# Specify parameters\n",
    "img_size = 128  # image size in square\n",
    "num_imgs = 2000  # number of images\n",
    "dtype = np.float32\n",
    "\n",
    "rank = 4\n",
    "c = rank + 1\n",
    "vols = LegacyVolume(\n",
    "    L=img_size,\n",
    "    C=c,\n",
    "    dtype=dtype,\n",
    ").generate()\n",
    "vols -= np.mean(vols,axis=0)\n",
    "class DummyFilter():\n",
    "    def __init__(self,const):\n",
    "        self.const = const\n",
    "    def evaluate_grid(self,L):\n",
    "        return np.ones((L,L)) * self.const\n",
    "sim = Simulation(\n",
    "    #unique_filters=[RadialCTFFilter(defocus=d) for d in np.linspace(1.5e4, 2.5e4, 7)],\n",
    "    #unique_filters = [DummyFilter(0.1)],\n",
    "    n=num_imgs,\n",
    "    vols=vols,\n",
    "    dtype=dtype,\n",
    "    amplitudes=1,\n",
    "    offsets = 0\n",
    ")\n",
    "\n",
    "vectorsGD = torch.tensor(volsCovarEigenvec(vols),requires_grad = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from covar_sgd import CovarDataset,Covar,CovarTrainer\n",
    "cds = CovarDataset(sim,vectorsGD = vectorsGD)\n",
    "covar = Covar(resolution=img_size,rank=rank)#,vectors=vectorsGD.reshape((rank,img_size,img_size,img_size))/cds.im_norm_factor)\n",
    "batch_size = 3\n",
    "learning_rate = 1e-4\n",
    "momentum = 0.9\n",
    "reg = 1e-6 \n",
    "gamma_lr = 0.8\n",
    "gamma_reg = 0.8\n",
    "kwargs_dict = {'max_epochs' : 10, 'lr' : learning_rate,'momentum' : momentum,'optim_type' : 'SGD','reg' : reg,'gamma_lr': gamma_lr,'gamma_reg' : gamma_reg}\n",
    "#kwargs_dict = {'max_epochs' : 10, 'lr' : 1e-8,'momentum' : momentum,'optim_type' : 'Adam','reg' : reg,'gamma_lr': gamma_lr,'gamma_reg' : gamma_reg}\n",
    "device = torch.device('cuda:0')\n",
    "dataloader = torch.utils.data.DataLoader(cds,batch_size = batch_size,shuffle = False)#,collate_fn=dataset_collate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "from covar_distributed import trainParallel\n",
    "\n",
    "trainParallel(covar,cds,num_gpus = 8,batch_size = batch_size,**kwargs_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 , :   0%|          | 0/667 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "diag(): Supports 1D or 2D tensors. Got 3D",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      2\u001b[0m trainer \u001b[38;5;241m=\u001b[39m CovarTrainer(covar,dataloader,device)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/home/roaiyadgar/thesis/covar_sgd.py:136\u001b[0m, in \u001b[0;36mCovarTrainer.train\u001b[0;34m(self, max_epochs, lr, momentum, optim_type, reg, gamma_lr, gamma_reg, orthogonal_projection)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreg \u001b[38;5;241m=\u001b[39m reg\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_epochs):\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreg \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m gamma_reg\n\u001b[1;32m    139\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/scratch/home/roaiyadgar/thesis/covar_sgd.py:108\u001b[0m, in \u001b[0;36mCovarTrainer.run_epoch\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_ims):\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnufft_plans[i]\u001b[38;5;241m.\u001b[39msetpts(pts_rot[i])\n\u001b[0;32m--> 108\u001b[0m cost_val,vectors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnufft_plans\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mnum_ims\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogTraining):\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m((batch_ind \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_log_freq \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)):\n",
      "File \u001b[0;32m/scratch/home/roaiyadgar/thesis/covar_sgd.py:86\u001b[0m, in \u001b[0;36mCovarTrainer.run_batch\u001b[0;34m(self, images, nufft_plans, filters)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_batch\u001b[39m(\u001b[38;5;28mself\u001b[39m,images,nufft_plans,filters):\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 86\u001b[0m     cost_val,vectors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcovar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnufft_plans\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;66;03m#print(torch.norm(vectors))\u001b[39;00m\n\u001b[1;32m     88\u001b[0m     cost_val\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/scratch/home/roaiyadgar/thesis/covar_sgd.py:192\u001b[0m, in \u001b[0;36mCovar.forward\u001b[0;34m(self, images, nufft_plans, filters, reg)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,images,nufft_plans,filters,reg):\n\u001b[0;32m--> 192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnufft_plans\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\u001b[43mreg\u001b[49m\u001b[43m)\u001b[49m,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectors\n",
      "File \u001b[0;32m/scratch/home/roaiyadgar/thesis/covar_sgd.py:188\u001b[0m, in \u001b[0;36mCovar.cost\u001b[0;34m(self, images, nufft_plans, filters, reg)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcost\u001b[39m(\u001b[38;5;28mself\u001b[39m,images,nufft_plans,filters,reg \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m--> 188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcost\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvectors\u001b[49m\u001b[43m,\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnufft_plans\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\u001b[43mreg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/home/roaiyadgar/thesis/covar_sgd.py:213\u001b[0m, in \u001b[0;36mcost\u001b[0;34m(vols, images, nufft_plans, filters, reg)\u001b[0m\n\u001b[1;32m    208\u001b[0m projvols_prod_term \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(projected_vols,projected_vols\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m    210\u001b[0m cost_val \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mpow(norm_squared_images,\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(torch\u001b[38;5;241m.\u001b[39mpow(images_projvols_term,\u001b[38;5;241m2\u001b[39m),dim\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m    211\u001b[0m             \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(torch\u001b[38;5;241m.\u001b[39mpow(projvols_prod_term,\u001b[38;5;241m2\u001b[39m),dim\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m)))\n\u001b[0;32m--> 213\u001b[0m norm_squared_projvols \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdiagonal(projvols_prod_term,dim1\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,dim2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    214\u001b[0m cost_val \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m noise_var \u001b[38;5;241m*\u001b[39m (torch\u001b[38;5;241m.\u001b[39msum(norm_squared_projvols,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m-\u001b[39mnorm_squared_images) \u001b[38;5;66;03m#+ (noise_var) ** 2\u001b[39;00m\n\u001b[1;32m    216\u001b[0m cost_val \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(cost_val,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: diag(): Supports 1D or 2D tensors. Got 3D"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "trainer = CovarTrainer(covar,dataloader,device)\n",
    "trainer.train(**kwargs_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from covar_analyzer import CovarAnalyzer\n",
    "import torch\n",
    "c = CovarAnalyzer.load('data/tmp2/results.csv')\n",
    "\n",
    "#c.plotCosineSim()\n",
    "#c.plotWeightedCosineSim()\n",
    "c.plotFroErr()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from projection_funcs import centered_fft2,vol_forward\n",
    "x = pickle.load(open('data/pts.bin','rb'))\n",
    "projs = x['projs'][0].reshape((rank,img_size,img_size))\n",
    "fft_projs = aspire.image.Image(np.abs(centered_fft2(torch.tensor(projs)).numpy()))\n",
    "projs = aspire.image.Image(projs)\n",
    "\n",
    "\n",
    "projs.show()\n",
    "fft_projs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nufft_plan import NufftPlan\n",
    "d = torch.device('cuda:1')\n",
    "plan = NufftPlan((img_size,)*3,batch_size = rank,gpu_device_id = d.index,gpu_method=1,gpu_sort = 0)\n",
    "plan.setpts(torch.tensor(x['pts']).to(d))\n",
    "vols = torch.tensor(x['vols']).to(d)\n",
    "proj_vols = vol_forward(vols,plan)\n",
    "p = aspire.image.Image(proj_vols.cpu().numpy())\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "p = (torch.remainder(cds.pts_rot + torch.pi , 2 * torch.pi) - torch.pi) - torch.tensor(x['pts'])\n",
    "#torch.tensor(x['pts']).shape\n",
    "ind = torch.argmin(torch.norm(p.reshape((2000,-1)),dim=1))\n",
    "aspire.utils.Rotation.from_matrix((sim.rotations[ind])).as_rotvec()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = fft_projs.asnumpy()[1].reshape(1,-1)\n",
    "a = np.argmax(fft_projs.asnumpy()[1])\n",
    "b[0,a]\n",
    "x['pts'][:,a]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aspire",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
