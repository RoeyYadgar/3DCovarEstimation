{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "isInteractiveWindowMessageCell": true
   },
   "source": [
    "Restarted aspire (Python 3.8.18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-13 17:59:16,984 INFO [aspire.source.image] Creating Simulation with 2000 images.\n"
     ]
    }
   ],
   "source": [
    "import aspire\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from aspire.operators import RadialCTFFilter\n",
    "from aspire.source.simulation import Simulation\n",
    "from aspire.volume import LegacyVolume, Volume\n",
    "from utils import volsCovarEigenvec\n",
    "import time\n",
    "from covar_estimation import im_stack_backward\n",
    "import torch\n",
    "# Specify parameters\n",
    "img_size = 28  # image size in square\n",
    "num_imgs = 2000  # number of images\n",
    "dtype = np.float32\n",
    "\n",
    "rank = 4\n",
    "c = rank + 1\n",
    "vols = LegacyVolume(\n",
    "    L=img_size,\n",
    "    C=c,\n",
    "    dtype=dtype,\n",
    ").generate()\n",
    "vols -= np.mean(vols,axis=0)\n",
    "sim = Simulation(\n",
    "    unique_filters=[RadialCTFFilter(defocus=d) for d in np.linspace(1.5e4, 2.5e4, 7)],\n",
    "    n=num_imgs,\n",
    "    vols=vols,\n",
    "    dtype=dtype,\n",
    "    amplitudes=1,\n",
    "    offsets = 0\n",
    ")\n",
    "\n",
    "vectorsGD = torch.tensor(volsCovarEigenvec(vols),requires_grad = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from covar_sgd import CovarDataset,Covar,CovarTrainer\n",
    "cds = CovarDataset(sim,vectorsGD = vectorsGD)\n",
    "covar = Covar(resolution=img_size,rank=rank)#,vectors=vectorsGD.reshape((rank,img_size,img_size,img_size))/cds.im_norm_factor)\n",
    "batch_size = 1\n",
    "learning_rate = 1e-4 \n",
    "momentum = 0.9\n",
    "reg = 1e-5\n",
    "gamma_lr = 0.8\n",
    "gamma_reg = 1\n",
    "kwargs_dict = {'max_epochs' : 10, 'lr' : learning_rate,'momentum' : momentum,'optim_type' : 'SGD','reg' : reg,'gamma_lr': gamma_lr,'gamma_reg' : gamma_reg}\n",
    "#kwargs_dict = {'max_epochs' : 10, 'lr' : 1e-10,'momentum' : momentum,'optim_type' : 'Adam','reg' : reg,'gamma_lr': gamma_lr,'gamma_reg' : gamma_reg}\n",
    "device = torch.device('cuda:0')\n",
    "dataloader = torch.utils.data.DataLoader(cds,batch_size = batch_size,shuffle = False)#,collate_fn=dataset_collate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "from covar_distributed import trainParallel\n",
    "\n",
    "trainParallel(covar,cds,num_gpus = 8,batch_size = batch_size,**kwargs_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 , cost value : 8.47e-01,  cosine sim : 0.10, frobenium norm error : 1.00e+00:  96%|█████████▌| 1924/2000 [03:11<00:07, 10.04it/s] \n",
      "Epoch 8 , cost value : 5.00e-01,  cosine sim : 0.52, frobenium norm error : 9.62e-01:  44%|████▍     | 879/2000 [01:25<01:48, 10.34it/s] \n",
      "Epoch 0 , cost value : 6.52e-01,  cosine sim : 0.82, frobenium norm error : 5.82e-01: 100%|██████████| 2000/2000 [00:12<00:00, 165.47it/s]\n",
      "Epoch 1 , cost value : 6.46e-01,  cosine sim : 0.86, frobenium norm error : 5.70e-01: 100%|██████████| 2000/2000 [00:10<00:00, 188.48it/s]\n",
      "Epoch 2 , cost value : 3.08e-01,  cosine sim : 0.86, frobenium norm error : 5.96e-01:   3%|▎         | 67/2000 [00:00<00:10, 190.79it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      2\u001b[0m trainer \u001b[38;5;241m=\u001b[39m CovarTrainer(covar,dataloader,device)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/home/roaiyadgar/thesis/covar_sgd.py:136\u001b[0m, in \u001b[0;36mCovarTrainer.train\u001b[0;34m(self, max_epochs, lr, momentum, optim_type, reg, gamma_lr, gamma_reg, orthogonal_projection)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreg \u001b[38;5;241m=\u001b[39m reg\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_epochs):\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreg \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m gamma_reg\n\u001b[1;32m    139\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/scratch/home/roaiyadgar/thesis/covar_sgd.py:109\u001b[0m, in \u001b[0;36mCovarTrainer.run_epoch\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_ims):\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnufft_plans[i]\u001b[38;5;241m.\u001b[39msetpts(pts_rot[i])\n\u001b[0;32m--> 109\u001b[0m cost_val,vectors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnufft_plans\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mnum_ims\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogTraining):\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m((batch_ind \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_log_freq \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)):\n",
      "File \u001b[0;32m/scratch/home/roaiyadgar/thesis/covar_sgd.py:89\u001b[0m, in \u001b[0;36mCovarTrainer.run_batch\u001b[0;34m(self, images, nufft_plans, filters)\u001b[0m\n\u001b[1;32m     87\u001b[0m cost_val,vectors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcovar\u001b[38;5;241m.\u001b[39mforward(images,nufft_plans,filters,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreg)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m#print(torch.norm(vectors))\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m \u001b[43mcost_val\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m#torch.nn.utils.clip_grad_value_(self.covar.parameters(), 10) #TODO : check for effect of gradient clipping\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/miniconda3/envs/aspire/lib/python3.8/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/aspire/lib/python3.8/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "trainer = CovarTrainer(covar,dataloader,device)\n",
    "trainer.train(**kwargs_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from covar_analyzer import CovarAnalyzer\n",
    "import torch\n",
    "c = CovarAnalyzer.load('data/tmp2/results.csv')\n",
    "\n",
    "#c.plotCosineSim()\n",
    "#c.plotWeightedCosineSim()\n",
    "c.plotFroErr()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from projection_funcs import centered_fft2,vol_forward\n",
    "x = pickle.load(open('data/pts.bin','rb'))\n",
    "projs = x['projs'][0].reshape((rank,img_size,img_size))\n",
    "fft_projs = aspire.image.Image(np.abs(centered_fft2(torch.tensor(projs)).numpy()))\n",
    "projs = aspire.image.Image(projs)\n",
    "\n",
    "\n",
    "projs.show()\n",
    "fft_projs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nufft_plan import NufftPlan\n",
    "d = torch.device('cuda:1')\n",
    "plan = NufftPlan((img_size,)*3,batch_size = rank,gpu_device_id = d.index,gpu_method=1,gpu_sort = 0)\n",
    "plan.setpts(torch.tensor(x['pts']).to(d))\n",
    "vols = torch.tensor(x['vols']).to(d)\n",
    "proj_vols = vol_forward(vols,plan)\n",
    "p = aspire.image.Image(proj_vols.cpu().numpy())\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "p = (torch.remainder(cds.pts_rot + torch.pi , 2 * torch.pi) - torch.pi) - torch.tensor(x['pts'])\n",
    "#torch.tensor(x['pts']).shape\n",
    "ind = torch.argmin(torch.norm(p.reshape((2000,-1)),dim=1))\n",
    "aspire.utils.Rotation.from_matrix((sim.rotations[ind])).as_rotvec()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = fft_projs.asnumpy()[1].reshape(1,-1)\n",
    "a = np.argmax(fft_projs.asnumpy()[1])\n",
    "b[0,a]\n",
    "x['pts'][:,a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import meanCTFPSD\n",
    "aspire.image.Image(cds.unique_filters.numpy()).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aspire",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
